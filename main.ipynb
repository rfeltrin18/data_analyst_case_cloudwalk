{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Business Case -- Cloudwalk \n",
    "\n",
    "## Data Analyst\n",
    "\n",
    "### Candidate: Rafael Feltrin\n",
    "\n",
    "Let's start by importing functions from the modules I wrote to perform the challenge's Parts I and II, which are respectively *etl_script.py* and *eda_script.py*."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9e342d7b7906b09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from scripts.etl_script import (read_csv, \n",
    "                                write_database_dates,\n",
    "                                write_associates_and_branches_cols,\n",
    "                                create_geodf)"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part I : ETL\n",
    "\n",
    "We must start by opening the .csv file, creating some new columns as we see fit -- they might be used here or could be nice to have in future analyses.\n",
    "\n",
    "So we begin we the *read_csv* method, which takes the file path and already does a simple change, which is filling the root CNPJ and the full CNPJ with leading zeroes in case they are missing.\n",
    "\n",
    "I always do that because this kind of data tends to end up in the hands of less tech-savvy areas such as sales ops and marketing and it is very common for them to match these CNPJ columns with manually collected spreadsheets or CRM outputs which commonly has the leading zeroes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c96b3cda35ba2df"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = read_csv(path=r'C:\\Users\\rafaf\\PycharmProjects\\data_analyst_case_cloudwalk\\data\\data_case_2024_03.csv',\n",
    "              sep=',',\n",
    "              zfill_cols=['document_number', 'cnpj_basico'])\n",
    "\n",
    "display(df.head(10))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e29a4bc2162bbc6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see it works.\n",
    "\n",
    "Next, we will convert the string-formatted to a database-friendly date format just in case we need it later. The *write_database_dates* function does that in a very modular fashion -- if we went back to the Roman calendar or added a new month we could only update the inputs!\n",
    "\n",
    "Back to the real world, we input the 12 months in Portuguese and run it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c2d07857a947039"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "portuguese_months = ['janeiro', 'fevereiro', 'mar√ßo', 'abril',\n",
    "                     'maio', 'junho', 'julho', 'agosto', \n",
    "                     'setembro', 'outubro', 'novembro', 'dezembro']\n",
    "\n",
    "month_numbers = [f\"{i:02d}\" for i in range(1, len(portuguese_months) + 1)]\n",
    "\n",
    "months = {name: num for name, num in zip(portuguese_months, month_numbers)}\n",
    "\n",
    "df = write_database_dates(df=df, \n",
    "                          date_col='opening_date', \n",
    "                          months=months)\n",
    "\n",
    "display(df['formatted_opening_date'].head(10))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8325b1f9ec27d2d3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another interesting column is the one with the amount of branches and associated. It is a JSON-like structure, and we parse it with the *write_associates_and_branches_cols* to add two new integer columns with the number of associates and branches.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa1fa3523f3f3502"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = write_associates_and_branches_cols(df=df,\n",
    "                                        json_col='total_branches_and_associates')\n",
    "\n",
    "display(df[['total_associates', 'total_branches']].head(10))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dde7d9ca228b13c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the cherry on top. Using the *geobr* package we can get official geospatial data from IPEA, which we will need when plotting map charts in Part II.\n",
    "\n",
    "The *create_geodf* function reads all IBGE city codes in the dataset and gets their geometry in a GeoDataFrame format, which we will later join with a pivot table of company data to plot the maps and show business insights.   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57f03c3611599e58"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gdf = create_geodf(df=df,\n",
    "                   city_code_col='city_code',\n",
    "                   year=2022)\n",
    "\n",
    "display(gdf.head(10))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c58027ab22abcff",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part II: EDA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62138c78475baedf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
